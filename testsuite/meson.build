# SPDX-License-Identifier: BSD-3-Clause
# Copyright 2022, Intel Corporation

subdir('tools')

# Setup envconfig files
write_file = find_program('../utils/write-file.py')
libfabric_libdir = libfabric_dep.get_variable('libdir')
libfabric_exec_prefix = libfabric_dep.get_variable('exec_prefix')
libndctl_libdir = libndctl_dep.get_variable('libdir')

# Create PKG_CONFIG_PATH variable in appropriate format
pkg_config_path_list = get_option('pkg_config_path')
pkg_config_path_str = ''
foreach s : pkg_config_path_list
    pkg_config_path_str = ':'.join(pkg_config_path_str, s)
endforeach

envconfig_py_content = f'''
# autogenerated file
config = {
    'GLOBAL_LIB_PATH': '@libfabric_libdir@:@libndctl_libdir@',
    'PMEM2_AVX512F_ENABLED': '@pmem2_use_avx512f@',
    'PMEM2_MOVDIR64B_ENABLED': '@pmem2_use_movdir64b@',
    'GLOBAL_PATH': '@libfabric_exec_prefix@/bin',
    'GLOBAL_PKG_CONFIG_PATH': '@pkg_config_path_str@'
}
'''

envconfig_sh_content = f'''
# autogenerated file
GLOBAL_LIB_PATH=@libfabric_libdir@:@libndctl_libdir@
GLOBAL_PATH=@libfabric_exec_prefix@/bin
GLOBAL_PKG_CONFIG_PATH=@pkg_config_path_str@
'''

debug('pkg_config_path_list:')
debug(pkg_config_path_list)
debug('pkg_config_path_str:')
debug(pkg_config_path_str)
debug('envconfig_sh_content:')
debug(envconfig_sh_content)

envconfig_sh = run_command(
    write_file,
    'envconfig.py',
    envconfig_py_content,
    check: true,
)

envconfig_sh = run_command(
    write_file,
    'envconfig.sh',
    envconfig_sh_content,
    check: true,
)

# Setup run-tests target
run_tests_python = find_program('RUNTESTS.py')
run_tests_bash = find_program('RUNTESTS')
run_tests_powershell = find_program('RUNTESTS.PS1')
run_tests_python_args = []
run_tests_bash_args = []
run_tests_powershell_args = []
run_tests_env = {}
run_tests_python_env = {}
run_tests_bash_env = {}
run_tests_powershell_env = {}

# Translate meson_options to python/bash/powershell arguments

# Option: tests-case
tests_case = get_option('tests-case')
if tests_case != ''
    run_tests_python_args += tests_case
    run_tests_bash_args += tests_case
    run_tests_powershell_args += tests_case
endif

# Option: tests-fs-dir-force-pmem
tests_fs_dir_force_pmem = get_option('tests-fs-dir-force-pmem')
if tests_fs_dir_force_pmem
    # I think we can do it here instead of RUNTESTS.*
    run_tests_env += {'PMEM_IS_PMEM_FORCE':'1'}
endif

# Option: tests-suite-log-level
tests_suite_log_level = get_option('tests-suite-log-level')
run_tests_python_args += f'--unittest_log_level=@tests_suite_log_level@'
if tests_suite_log_level == 2
    run_tests_bash_args += '-v'
    run_tests_powershell_args += '-Verbose'
endif

# Option: tests-keep-going'
tests_keep_going = get_option('tests-keep-going')
if tests_keep_going
    run_tests_python_args += '--keep_going'
    run_tests_bash_env += {'KEEP_GOING':'1'}
    # this option is not supported in powershell I think
endif

# Option: tests-granularity
tests_granularity = get_option('tests-granularity')
if tests_granularity != 'any'
    run_tests_python_args += f'-g=@tests_granularity@'
    if tests_granularity == 'page'
        run_tests_bash_args += '-f=nonpmem'
        run_tests_powershell_args += '-f=non-pmem'
    elif tests_granularity == 'cacheline' or tests_granularity == 'byte'
        run_tests_bash_args += '-f=pmem'
        run_tests_powershell_args += '-f=pmem'
    elif tests_granularity == 'non'
        run_tests_bash_args += '-f=none'
    endif
endif

# Option: tests-type
tests_type = get_option('tests-type')
if tests_type != 'check'
    run_tests_python_args += f'-t=@tests_type@'
    run_tests_bash_args += f'-t=@tests_type@'
    run_tests_powershell_args += f'-t=@tests_type@'
endif

# Option: tests-timeout
tests_timeout = get_option('tests-timeout')
if tests_timeout != ''
    run_tests_python_args += f'-o@tests_timeout@'
    run_tests_bash_args += f'-o@tests_timeout@'
    run_tests_powershell_args += f'-o@tests_timeout@'
endif

# Option: tests-sequence
tests_sequence = get_option('tests-sequence')
if tests_sequence != ''
    run_tests_python_args += f'-u=@tests_sequence@'
    run_tests_bash_args += f'-u=@tests_sequence@'
    run_tests_powershell_args += f'-u=@tests_sequence@'
endif

# Option: tests-list-cases
tests_list_cases = get_option('tests-list-cases')
if tests_list_cases
    run_tests_python_args += '--list-testcases'
endif

# Option: tests-fail-on-skip
tests_fail_on_skip = get_option('tests-fail-on-skip')
if tests_fail_on_skip
    run_tests_python_args += '--fail-on-skip'
endif


# Option: tests-tracer
tests_tracer = get_option('tests-tracer')
if tests_tracer != ''
    run_tests_python_args += f'--tracer=@tests_tracer@'
    # TODO: Check if it works
    run_tests_bash_env += {'TRACER': tests_tracer}
    # Not sure if there is an equivalent in bash and powershell
endif

# Setup run_tests framework build types based on meson options
build_type = get_option('buildtype')
default_library = get_option('default_library')
if build_type == 'debug'
    if default_library == 'shared'
        run_tests_python_args += '-b=debug'
        run_tests_bash_args += '-b'
        run_tests_bash_args += 'debug'
    else
        run_tests_python_args += '-b=static_debug'
        run_tests_bash_args += '-bstatic-debug'
    endif
    run_tests_powershell_args += '-b=debug'
elif build_type == 'release'
    if default_library == 'shared'
        run_tests_python_args += '-b=release'
        run_tests_bash_args += '-bnondebug'
    else
        run_tests_python_args += '-b=static_release'
        run_tests_bash_args += '-b=static-nondebug'
    endif
    run_tests_powershell_args += '-b=nondebug'
elif build_type == 'debugoptimized'
    if default_library == 'shared'
        run_tests_python_args += '-b=debugoptimized'
        run_tests_bash_args += '-bdebugoptimized'
    else
        run_tests_python_args += '-b=static_debugoptimized'
        run_tests_bash_args += '-bstatic-debugoptimized'
    endif
    run_tests_powershell_args += '-b=debugoptimized'
else
    error(f'Tests framework does not support @build_type@ build type.')
endif

# Create targets specific for each framework
debug('run-tests-python args:')
debug(run_tests_python_args)
debug('run-tests-python env:')
debug(run_tests_python_env)
run_tests_python_target = run_target(
    'run-tests-python',
    command:[run_tests_python]+run_tests_python_args,
    env:run_tests_env+run_tests_python_env,
    depends:copy_targets,
)

debug('run-tests-bash args:')
debug(run_tests_bash_args)
debug('run-tests-bash env:')
debug(run_tests_bash_env)
run_tests_bash_target = run_target(
    'run-tests-bash',
    command:[run_tests_bash]+run_tests_bash_args,
    env:run_tests_env+run_tests_bash_env,
    depends:copy_targets,
)

debug('run-tests-powershell args:')
debug(run_tests_powershell_args)
debug('run-tests-powershell env:')
debug(run_tests_powershell_env)
run_tests_powershell_target = run_target(
    'run-tests-powershell',
    command:[run_tests_powershell]+run_tests_powershell_args,
    env:run_tests_env+run_tests_powershell_env,
    depends:copy_targets,
)

# If test case was specified we run only one framework
run_tests_targets = []
if tests_case != ''
    if fs.exists(meson.project_build_root() / 'src/test' / tests_case / 'TESTS.py')
        # Selected case is using python
        run_tests_targets += run_tests_python_target
    elif host_machine.system() == 'linux' and fs.exists(meson.project_build_root() / 'src/test' / tests_case / 'TEST0')
        # Selected case is using bash
        run_tests_targets += run_tests_bash_target
    elif host_machine.system() == 'windows' and fs.exists(meson.project_build_root() / 'src/test' / tests_case / 'TEST0.PS1')
        # Selected case is using powershell
        run_tests_targets += run_tests_powershell_target
    else
        error(f'No such test case: @tests_case@')
    endif
else
    # Else, we run all available on the host machine
    run_tests_targets += run_tests_python_target
    if host_machine.system() == 'windows'
        run_tests_targets += run_tests_powershell_target
    else
        # We expect systems different than windows to be able to run bash
        run_tests_targets += run_tests_bash_target
    endif
endif

tests_target = alias_target(
    'run-tests',
    run_tests_targets,
)